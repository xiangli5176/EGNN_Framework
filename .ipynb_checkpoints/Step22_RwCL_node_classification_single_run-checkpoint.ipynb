{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import random\n",
    "from time import perf_counter\n",
    "import yaml\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import logging\n",
    "import shutil\n",
    "import ast\n",
    "\n",
    "from lib_EGNN_Pytorch.models.model_app import RwCL_Model\n",
    "from lib_EGNN_Pytorch import utils, evaluation\n",
    "from lib_EGNN_Pytorch.data_preprocessing import Pre_utils, GBP_precompute\n",
    "\n",
    "from lib_EGNN_Pytorch.app.RwCL import basic_exec_node_classification\n",
    "from lib_EGNN_Pytorch.app.RwCL import RwCL_app\n",
    "\n",
    "# from lib_EGNN_Pytorch.app.RwSL import basic_exec_cluster\n",
    "# from lib_EGNN_Pytorch.app.RwSL import RwSL_app\n",
    "# from lib_EGNN_Pytorch.app.RwCL.multi_exec import run_train_cluster, run_test_cluster\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Set up logging\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s (%(levelname)s): %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>> Setting Tuning :\n",
      "Tune param : nothing ; with the following values: [1]\n",
      ">>>>>>>>>>>>>>>>>>>> Loading configs :\n",
      "data_name    :    cora\n",
      "n_class    :    7\n",
      "feat_dim    :    1433\n",
      "seed    :    39788\n",
      "lr    :    0.0001\n",
      "enc_arch    :    256-128\n",
      "mlp_arch    :    256-\n",
      "num_proj_hidden    :    512\n",
      "tau    :    1.0\n",
      "drop_feature_rate_1    :    0.08\n",
      "view_num    :    3\n",
      "num_epochs    :    300\n",
      "weight_decay    :    0.02\n",
      "batch_size_train    :    512\n",
      "eval_display    :    10\n",
      "loss_batch_size    :    0\n",
      "alpha    :    0.1\n",
      "rmax    :    1e-06\n",
      "rrz    :    0.4\n",
      "batchnorm    :    False\n",
      "dropout_rate    :    0.1\n",
      "reg_lr    :    0.2\n",
      "reg_num_epochs    :    100\n",
      "reg_weight_decay    :    1e-05\n",
      "reg_dropout_rate    :    0\n",
      "reg_eval_step    :    1\n",
      "reg_early_stop    :    False\n"
     ]
    }
   ],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>> Setting input data and configurations:\n",
    "tkipf_graph_path = \"/home/xiangli/projects/tmpdata/GCN/Graph_Clustering/tkipf_gcn_data\"\n",
    "shchur_graph_path = \"/home/xiangli/projects/tmpdata/GCN/Graph_Clustering/shchur_gnnbenchmark_data/npz\"\n",
    "sdcn_data_path = \"/home/xiangli/projects/tmpdata/GCN/Graph_Clustering/sdcn/\"\n",
    "\n",
    "data_name = 'cora'\n",
    "# data_name = 'cite'\n",
    "\n",
    "workdir = f\"/home/xiangli/projects/GCN_program/Workshop_local/EGNN_workdir_results/RwCL/{data_name}/node_classification/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config_file_name = f'config_{data_name.lower()}.yaml'\n",
    "config_file_path = os.path.join('./config_data_RwCL_classification/', config_file_name)\n",
    "with open(config_file_path, 'r') as c:\n",
    "    config = yaml.safe_load(c)    \n",
    "    \n",
    "# For strings that yaml doesn't parse (e.g. None)\n",
    "for key, val in config.items():\n",
    "    if type(val) is str:\n",
    "        try:\n",
    "            config[key] = ast.literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass\n",
    "\n",
    "torch.manual_seed(config['seed'])\n",
    "random.seed(12345)        \n",
    "        \n",
    "print(\">>>>>>>>>>>>>>>>>>>> Setting Tuning :\")\n",
    "tune_param_name = \"nothing\"\n",
    "# tune_param_name = \"n_epochs\"\n",
    "\n",
    "tune_val_label_list = [1]\n",
    "# tune_val_label_list = [0.0, 0.1, 0.2, 0.5]\n",
    "\n",
    "# tune_val_list = [10**(-val) for val in tune_val_label_list]\n",
    "tune_val_list = [val for val in tune_val_label_list]\n",
    "\n",
    "# trainer_id_list = [0]\n",
    "trainer_id_list = list(range(1))\n",
    "\n",
    "print(f\"Tune param : {tune_param_name} ; with the following values: {tune_val_list}\")\n",
    "\n",
    "print(\">>>>>>>>>>>>>>>>>>>> Loading configs :\")\n",
    "for key, val in config.items():\n",
    "    print(f\"{key}    :    {val}\")\n",
    "    \n",
    "# =================== copy the config file: =======================================\n",
    "dest_folder = os.path.dirname(os.path.join(workdir, f\"tune_{tune_param_name}/\"))\n",
    "if not os.path.exists(os.path.join(dest_folder, config_file_name)):    \n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    shutil.copyfile(config_file_path,  os.path.join(dest_folder, config_file_name))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use tkipf dataset: Cora, PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packed data already exists at: /home/xiangli/projects/tmpdata/GCN/Graph_Clustering/tkipf_gcn_data/Packed_data/no_row_normalize/cora, LOADING...\n",
      "Loading the pre-existent adj_GBP_file at : /home/xiangli/projects/tmpdata/GCN/Graph_Clustering/tkipf_gcn_data/Packed_data/no_row_normalize/cora/cython_GBP_input/cora_adj.npy\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Cython_GBP_data_path = f\"/home/xiangli/projects/tmpdata/GCN/Graph_Clustering/tkipf_gcn_data/Packed_data/no_row_normalize/{data_name.lower()}/cython_GBP_input/\"\n",
    "node_adj_GBP_file = os.path.join(Cython_GBP_data_path, f'{data_name.lower()}_adj.npy')\n",
    "\n",
    "\n",
    "adj_full, features, labels_full, node_index = Pre_utils.load_gcn_tkipf_data(tkipf_graph_path, \n",
    "                                                        data_name.lower(), normalize = False, redo_save = False)\n",
    "\n",
    "features, adj_matrix_cython = Pre_utils.load_Cython_GBP_input_node(data_name, features, adj_full, \n",
    "                            adj_GBP_file_path = node_adj_GBP_file, directed = False, redo_save = False)              \n",
    "\n",
    "idx_train, idx_val, idx_test = node_index[\"train_index\"], node_index[\"val_index\"], node_index[\"test_index\"]\n",
    "\n",
    "print(sum(adj_full.diagonal()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pre-computation time cost is 39.26646812699619 seconds! \n"
     ]
    }
   ],
   "source": [
    "features_GBP = GBP_precompute.precompute_Cython_GBP_feat(data_name, 40, \n",
    "                                config[\"alpha\"], config[\"rmax\"], config[\"rrz\"], \n",
    "                                rwnum = 0, directed = False, add_self_loop = False,\n",
    "                                rand_seed = 10, \n",
    "                                feats = features, adj_matrix = adj_matrix_cython)\n",
    "\n",
    "tune_val_label = tune_val_label_list[0]\n",
    "tune_val = tune_val_list[0]\n",
    "trainer_id = trainer_id_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform train cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train = [features_GBP, labels_full, idx_train, idx_val, idx_test]\n",
    "input_data_test = [labels_full, idx_test]\n",
    "\n",
    "model = RwCL_Model(config)\n",
    "\n",
    "checkpoint_file_path = os.path.join(workdir,\n",
    "                f\"tune_{tune_param_name}/model_checkpoint/tunelabel_{tune_val_label}_trainer_{trainer_id}/best_model.pkl\")\n",
    "\n",
    "if os.path.exists(checkpoint_file_path):\n",
    "    print(\"ckpt file already exists, so removed ...\")\n",
    "    os.remove(checkpoint_file_path)\n",
    "else:\n",
    "    os.makedirs(os.path.dirname(checkpoint_file_path), exist_ok=True)\n",
    "\n",
    "val_metric_path = os.path.join(workdir, \n",
    "                            f\"tune_{tune_param_name}/val_metric/tunelabel_{tune_val_label}_trainer_{trainer_id}/val_metric.pkl\")\n",
    "\n",
    "# ==========================  Start the training ==========================\n",
    "time_training, metric_summary = basic_exec_node_classification.train(model, config, input_data_train, device = device, checkpoint_file_path = checkpoint_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Test cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = RwCL_Model(config)\n",
    "\n",
    "checkpoint_file_path = os.path.join(workdir,\n",
    "                f\"tune_{tune_param_name}/model_checkpoint/tunelabel_{tune_val_label}_trainer_{trainer_id}/best_model.pkl\")\n",
    "\n",
    "if not os.path.exists(os.path.dirname(checkpoint_file_path)):\n",
    "    raise(\"checkpoint file is missing\")\n",
    "\n",
    "test_metric_path = os.path.join(workdir,\n",
    "                f\"tune_{tune_param_name}/test_metric/tunelabel_{tune_val_label}_trainer_{trainer_id}/test_metric.pkl\")\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>> Start test inference\n",
    "test_time, test_metric = basic_exec_node_classification.test(config, input_data_test, \n",
    "                            device = \"cpu\", checkpoint_file_path = checkpoint_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform train cluster from a class defined from the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = RwCL_app.RwCL_framework(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train = [features_GBP, labels_full, idx_train, idx_val, idx_test]\n",
    "input_data_test = [labels_full, idx_test]\n",
    "\n",
    "model = RwCL_Model(config)\n",
    "\n",
    "checkpoint_file_path = os.path.join(workdir,\n",
    "                f\"tune_{tune_param_name}/model_checkpoint/tunelabel_{tune_val_label}_trainer_{trainer_id}/best_model.pkl\")\n",
    "\n",
    "if os.path.exists(checkpoint_file_path):\n",
    "    print(\"ckpt file already exists, so removed ...\")\n",
    "    os.remove(checkpoint_file_path)\n",
    "else:\n",
    "    os.makedirs(os.path.dirname(checkpoint_file_path), exist_ok=True)\n",
    "\n",
    "val_metric_path = os.path.join(workdir, \n",
    "                            f\"tune_{tune_param_name}/val_metric/tunelabel_{tune_val_label}_trainer_{trainer_id}/val_metric.pkl\")\n",
    "\n",
    "# ==========================  Start the training ==========================\n",
    "time_training, metric_summary = obj.train_node_classification(model, config, input_data_train, device = device, \n",
    "                                                              checkpoint_file_path = checkpoint_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = RwCL_Model(config)\n",
    "\n",
    "checkpoint_file_path = os.path.join(workdir,\n",
    "                f\"tune_{tune_param_name}/model_checkpoint/tunelabel_{tune_val_label}_trainer_{trainer_id}/best_model.pkl\")\n",
    "\n",
    "if not os.path.exists(os.path.dirname(checkpoint_file_path)):\n",
    "    raise(\"checkpoint file is missing\")\n",
    "\n",
    "test_metric_path = os.path.join(workdir,\n",
    "                f\"tune_{tune_param_name}/test_metric/tunelabel_{tune_val_label}_trainer_{trainer_id}/test_metric.pkl\")\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>> Start test inference\n",
    "test_time, test_metric = obj.test_node_classification(config, input_data_test, \n",
    "                            device = \"cpu\", checkpoint_file_path = checkpoint_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # free GPU memory\n",
    "# !(nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9 )\n",
    "# !(nvidia-smi | grep 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch1.7]",
   "language": "python",
   "name": "conda-env-pytorch1.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
